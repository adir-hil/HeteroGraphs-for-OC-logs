{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adir-hil/HeteroGraphs-for-OC-logs/blob/main/Baseline_production.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Package installation & import"
      ],
      "metadata": {
        "id": "I2BUGbfingDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.4\n",
        "!pip install catboost --force-reinstall"
      ],
      "metadata": {
        "id": "xBiYAdElxv0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MPpxVFVLmnL",
        "outputId": "23284312-b0ba-431b-c847-12dec93f6a15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/ocel\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)\n",
        "%cd gdrive/MyDrive/ocel\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np # For sqrt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing & Dataset split"
      ],
      "metadata": {
        "id": "d9QzIpL5nuFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_df_lc = pd.read_csv('/content/gdrive/MyDrive/ocel/with_lables.csv')\n",
        "new_df_lc['LIFECYCLE_BATCH'] = new_df_lc['LIFECYCLE_BATCH'].astype(str)\n",
        "new_df_lc['TIMESTAMP'] = pd.to_datetime(new_df_lc['TIMESTAMP'])\n",
        "new_df_lc.drop(\"Unnamed: 0\",axis=1,inplace =True)\n",
        "new_df_lc.drop(\"Unnamed: 0.1\",axis=1,inplace =True)\n",
        "\n",
        "# Get the order of batches based on the first timestamp of each batch\n",
        "batch_order = new_df_lc.groupby('LIFECYCLE_BATCH')['TIMESTAMP'].min().sort_values().index\n",
        "# Reindex the dataframe based on the batch order\n",
        "new_df_lc = new_df_lc.set_index('LIFECYCLE_BATCH').loc[batch_order].reset_index()\n",
        "\n",
        "# Calculate the first timestamp in the dataframe\n",
        "first_timestamp = new_df_lc['TIMESTAMP'].min()\n",
        "\n",
        "# Create a new column called 'DAYS_FROM_FIRST_EVENT'\n",
        "new_df_lc['DAYS_FROM_FIRST_EVENT'] = (new_df_lc['TIMESTAMP'] - first_timestamp).dt.days"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXxkjfS9sGS8",
        "outputId": "8dcd1996-5faf-431a-956b-a3acf6c91da1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-cf89208f6960>:1: DtypeWarning: Columns (3,9,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  new_df_lc = pd.read_csv('/content/gdrive/MyDrive/ocel/with_lables.csv')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_train_batches = 815\n",
        "n_val_batches = 116\n",
        "unique_batches = new_df_lc['LIFECYCLE_BATCH'].unique()\n",
        "n_total_unique_batches = len(unique_batches)\n",
        "\n",
        "print(f\"\\nTotal unique batches found: {n_total_unique_batches}\")\n",
        "if n_train_batches + n_val_batches > n_total_unique_batches:\n",
        "      print(f\"Warning: Train+Val batches ({n_train_batches + n_val_batches}) exceeds total ({n_total_unique_batches}). Adjusting Val size.\")\n",
        "      n_val_batches = n_total_unique_batches - n_train_batches\n",
        "      n_val_batches = max(0, n_val_batches) # Ensure non-negative\n",
        "\n",
        "train_batch_ids = unique_batches[0 : n_train_batches]\n",
        "val_batch_ids = unique_batches[n_train_batches : n_train_batches + n_val_batches]\n",
        "test_batch_ids = unique_batches[n_train_batches + n_val_batches : ]\n",
        "\n",
        "print(f\"Assigning {len(train_batch_ids)} batches to Train.\")\n",
        "print(f\"Assigning {len(val_batch_ids)} batches to Validation.\")\n",
        "print(f\"Assigning {len(test_batch_ids)} batches to Test.\")\n",
        "\n",
        "train_set = set(train_batch_ids)\n",
        "val_set = set(val_batch_ids)\n",
        "test_set = set(test_batch_ids)\n",
        "\n",
        "new_df_lc['SET'] = 'Unknown' # Initialize\n",
        "new_df_lc.loc[new_df_lc['LIFECYCLE_BATCH'].isin(train_set), 'SET'] = 'Train'\n",
        "new_df_lc.loc[new_df_lc['LIFECYCLE_BATCH'].isin(val_set), 'SET'] = 'Val'\n",
        "new_df_lc.loc[new_df_lc['LIFECYCLE_BATCH'].isin(test_set), 'SET'] = 'Test'\n",
        "\n",
        "print(\"\\nData distribution across sets:\")\n",
        "print(new_df_lc['SET'].value_counts())\n",
        "if (new_df_lc['SET'] == 'Unknown').any():\n",
        "    print(\"\\nError: Some rows were not assigned to a set. Check batch IDs.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LAy_PbHiYN-",
        "outputId": "1aa22434-3e89-48e6-d48a-109fb9df63cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total unique batches found: 1165\n",
            "Assigning 815 batches to Train.\n",
            "Assigning 116 batches to Validation.\n",
            "Assigning 234 batches to Test.\n",
            "\n",
            "Data distribution across sets:\n",
            "SET\n",
            "Train    372848\n",
            "Test     105793\n",
            "Val       46988\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_column = 'log_days_to_finish'\n",
        "\n",
        "# List the exact column names you want to use as input features\n",
        "feature_columns = [\n",
        "    'ITEM',            # Potentially categorical ID? Treat as numeric or categorical? Let's try categorical.\n",
        "    'AREA',            # Categorical\n",
        "    'LOCATION',        # Categorical\n",
        "    'TU',              # Categorical ID\n",
        "    'PMX_USER',        # Categorical ID\n",
        "    'PMX_ORDER',       # Potentially categorical ID? Let's try categorical.\n",
        "    'ORDER_STEP',      # Potentially categorical ID? Let's try categorical.\n",
        "    'ACTIVITY',        # Categorical (redundant with MAIN/SUB?)\n",
        "    'LOT',             # Potentially categorical ID? Let's try categorical.\n",
        "    'PRODUCT',         # Potentially categorical ID? Let's try categorical.\n",
        "    'MATERIAL',        # Potentially categorical ID? Let's try categorical.\n",
        "    'LIFECYCLE_BATCH',\n",
        "    # Include your hour columns if desired\n",
        "    'hour_0', 'hour_1', 'hour_2', 'hour_3', 'hour_4', 'hour_5', 'hour_6', 'hour_7',\n",
        "    'hour_8', 'hour_9', 'hour_10', 'hour_11', 'hour_12', 'hour_13', 'hour_14', 'hour_15',\n",
        "    'hour_16', 'hour_17', 'hour_18', 'hour_19', 'hour_20', 'hour_21', 'hour_22', 'hour_23',\n",
        "    # Include your tertile columns if desired\n",
        "    'tertile_12am-8am', 'tertile_8am-4pm', 'tertile_4pm-12am',\n",
        "    # Include your time features if desired\n",
        "    'time_since_first_day',\n",
        "    'grouped_time_since_first_day',\n",
        "]\n",
        "    # 'DAYS_FROM_FIRST_EVENT', # Include if calculated and desired\n",
        "    # Ensure 'days_to_finish' (the non-log version) is NOT included if 'log_days_to_finish' is the target]\n",
        "\n",
        "# Identify which of the chosen feature_columns are categorical\n",
        "# *** USER ACTION REQUIRED HERE: Verify this list is correct for your chosen features ***\n",
        "categorical_features_list = [\n",
        "    'ITEM','AREA', 'LOCATION', 'TU',\n",
        "    'PMX_USER', 'PMX_ORDER', 'ORDER_STEP', 'ACTIVITY', 'LOT',\n",
        "    'PRODUCT', 'MATERIAL','LIFECYCLE_BATCH'\n",
        "    # Add/remove based on the actual feature_columns list and their types\n",
        "    # Ensure USAGE/PROD_TYPE are added if they are categorical strings/objects\n",
        "]\n",
        "\n",
        "# Basic check for missing definitions\n",
        "if not target_column or not feature_columns:\n",
        "    print(\"Error: Please define `target_column` and `feature_columns`.\")\n",
        "    exit()\n",
        "\n",
        "# Verify all feature columns exist in the DataFrame\n",
        "missing_cols = [col for col in feature_columns if col not in new_df_lc.columns]\n",
        "if missing_cols:\n",
        "    print(f\"Error: The following feature columns are not in the DataFrame: {missing_cols}\")\n",
        "    exit()\n",
        "\n",
        "# Verify target column exists\n",
        "if target_column not in new_df_lc.columns:\n",
        "    print(f\"Error: The target column '{target_column}' is not in the DataFrame.\")\n",
        "    exit()\n",
        "\n",
        "# Verify categorical features are within the main feature list\n",
        "missing_cats = [col for col in categorical_features_list if col not in feature_columns]\n",
        "if missing_cats:\n",
        "    print(f\"Error: The following categorical features are not in the main feature_columns list: {missing_cats}\")\n",
        "    exit()\n"
      ],
      "metadata": {
        "id": "_Ei7G-XOjlA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in categorical_features_list:\n",
        "  # Convert the column to a categorical type and extract numerical codes\n",
        "  new_df_lc[col] = new_df_lc[col].astype('category')\n",
        "  new_df_lc[col] = new_df_lc[col].cat.codes"
      ],
      "metadata": {
        "id": "6n_9z35K7MJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nSplitting data into Train/Validation/Test sets (X and y)...\")\n",
        "\n",
        "train_df = new_df_lc[new_df_lc['SET'] == 'Train']\n",
        "val_df   = new_df_lc[new_df_lc['SET'] == 'Val']\n",
        "test_df  = new_df_lc[new_df_lc['SET'] == 'Test']\n",
        "\n",
        "X_train = train_df[feature_columns]\n",
        "y_train = train_df[target_column]\n",
        "\n",
        "X_val = val_df[feature_columns]\n",
        "y_val = val_df[target_column]\n",
        "\n",
        "X_test = test_df[feature_columns]\n",
        "y_test = test_df[target_column]\n",
        "\n",
        "print(f\"Train shapes: X={X_train.shape}, y={y_train.shape}\")\n",
        "print(f\"Val shapes:   X={X_val.shape}, y={y_val.shape}\")\n",
        "print(f\"Test shapes:  X={X_test.shape}, y={y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjBI18yFkh50",
        "outputId": "268c99f5-b9a9-47d5-a71d-25100a7df8b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Splitting data into Train/Validation/Test sets (X and y)...\n",
            "Train shapes: X=(372848, 41), y=(372848,)\n",
            "Val shapes:   X=(46988, 41), y=(46988,)\n",
            "Test shapes:  X=(105793, 41), y=(105793,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Initialization & Execution"
      ],
      "metadata": {
        "id": "_MLJ3MaUoOB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nInitializing CatBoostRegressor...\")\n",
        "\n",
        "# Define model parameters (adjust as needed)\n",
        "catboost_params = {\n",
        "    'iterations': 1000,             # Number of boosting iterations (trees)\n",
        "    'learning_rate': 0.05,          # Step size shrinkage\n",
        "    'depth': 6,                     # Depth of trees\n",
        "    'l2_leaf_reg': 3,               # L2 regularization coefficient\n",
        "    'loss_function': 'MAE',        # Objective function for regression\n",
        "    'eval_metric': 'MAE',          # Metric for evaluation and early stopping\n",
        "    'cat_features': categorical_features_list, # List of categorical feature names\n",
        "    'early_stopping_rounds': 50,    # Stop if eval_metric doesn't improve for 50 rounds\n",
        "    'random_seed': 42,              # For reproducibility\n",
        "    'verbose': 100,                 # Print progress every 100 iterations\n",
        "    # 'nan_mode': 'Min'             # How CatBoost handles NaNs internally if not pre-filled\n",
        "                                    # (Can be 'Min', 'Max', 'Forbidden')\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WA3XfpfF65jh",
        "outputId": "2e312b3a-efb5-4c44-a44a-e208444166f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Initializing CatBoostRegressor...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_results = []\n",
        "val_results = []\n",
        "train_results = []\n",
        "\n",
        "# Set the random seed\n",
        "seeds = [1,2,3,4,5,6,7,8,9,10,11,12]\n",
        "for seed in seeds:\n",
        "    # Make a copy of the fixed parameters and update the random_seed\n",
        "    params = catboost_params.copy()\n",
        "    params['random_seed'] = seed  # CatBoost uses 'random_seed' as the parameter name\n",
        "    # Initialize the CatBoostRegressor using the parameters\n",
        "    model = CatBoostRegressor(**params)\n",
        "    print(\"Training CatBoost model...\")\n",
        "    # Train the model using the training set\n",
        "    # Evaluate performance on the validation set during training for early stopping\n",
        "    model.fit(X_train, y_train, eval_set=(X_val, y_val), verbose=False)\n",
        "              # cat_features parameter passed during init is usually sufficient,\n",
        "              # but can be passed here too for clarity:\n",
        "              # cat_features=categorical_features_list\n",
        "    print(\"\\nTraining finished.\")\n",
        "    print(f\"Best iteration found: {model.get_best_iteration()}\")\n",
        "    predictions = model.predict(X_val)\n",
        "    mae_train = model.best_score_['learn']['MAE']\n",
        "    mae_val = model.best_score_['validation']['MAE']\n",
        "    # Save results\n",
        "    mae_test = mean_absolute_error(y_val, predictions)\n",
        "    # Save results\n",
        "    test_results.append({'seed': seed, 'MAE_TEST': np.expm1(mae_test)})\n",
        "    val_results.append({'seed': seed, 'MAE_VAL': np.expm1(mae_val)})\n",
        "    train_results.append({'seed': seed, 'MAE_TRAIN': np.expm1(mae_train)})\n",
        "    print(f'Seed: {seed}, MAE_TEST: {np.expm1(mae_test)}')\n",
        "    print(f'Seed: {seed}, MAE_VAL: {np.expm1(mae_val)}')\n",
        "    print(f'Seed: {seed}, MAE_TRAIN: {np.expm1(mae_train)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        },
        "id": "C0Hrz-U07G_N",
        "outputId": "84c86748-ea82-403c-98e4-dcf17fc4acf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training CatBoost model...\n",
            "\n",
            "Training finished.\n",
            "Best iteration found: 53\n",
            "Seed: 1, MAE_TEST: 0.8316402357178724\n",
            "Seed: 1, MAE_VAL: 0.8316384058602675\n",
            "Seed: 1, MAE_TRAIN: 0.37920288908380084\n",
            "Training CatBoost model...\n",
            "\n",
            "Training finished.\n",
            "Best iteration found: 67\n",
            "Seed: 2, MAE_TEST: 0.8271508805877597\n",
            "Seed: 2, MAE_VAL: 0.8271490555153309\n",
            "Seed: 2, MAE_TRAIN: 0.36286673320228857\n",
            "Training CatBoost model...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-e33b685496b1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Train the model using the training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Evaluate performance on the validation set during training for early stopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m               \u001b[0;31m# cat_features parameter passed during init is usually sufficient,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m               \u001b[0;31m# but can be passed here too for clarity:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'loss_function'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5872\u001b[0m             \u001b[0mCatBoostRegressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_compatible_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_function'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5873\u001b[0;31m         return self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline,\n\u001b[0m\u001b[1;32m   5874\u001b[0m                          \u001b[0muse_best_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5875\u001b[0m                          \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2409\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mplot_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Training plots'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_get_train_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2410\u001b[0;31m                 self._train(\n\u001b[0m\u001b[1;32m   2411\u001b[0m                     \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2412\u001b[0m                     \u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eval_sets\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1790\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1791\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "print(math.expm1((model.best_score_['learn']['MAE'])))\n",
        "print(math.expm1((model.best_score_['validation']['MAE'])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f362wBRo9Ytf",
        "outputId": "650c95d3-e4d9-4173-a89f-266ff8ad31b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.37648751535222\n",
            "0.8332309119404723\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYQQR0xCZAAl",
        "outputId": "1e8a34b0-c5b6-45fd-fbb0-a0e2a8a8ac1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'seed': 1, 'MAE': 0.6052118690840198},\n",
              " {'seed': 2, 'MAE': 0.6027578577778933},\n",
              " {'seed': 3, 'MAE': 0.6271541933379294},\n",
              " {'seed': 4, 'MAE': 0.5849851187049623},\n",
              " {'seed': 5, 'MAE': 0.6114633528170189},\n",
              " {'seed': 6, 'MAE': 0.603006210448655},\n",
              " {'seed': 7, 'MAE': 0.5968650305419213},\n",
              " {'seed': 8, 'MAE': 0.600984902002711},\n",
              " {'seed': 9, 'MAE': 0.6184216266907516},\n",
              " {'seed': 10, 'MAE': 0.6021739210639081},\n",
              " {'seed': 11, 'MAE': 0.6178597953591217},\n",
              " {'seed': 12, 'MAE': 0.5993395977767381}]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8fXoXV54JqKaHbSvm1Me8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}